{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.Training import training_and_testing, loss_function\n",
    "from py.vae import NeuralNet as nnet\n",
    "import py.config as CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchinfo import summary\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rc('font', family='NanumGothic')\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_images(image):\n",
    "    # 이미지를 0도, 90도, 180도, 270도로 회전시키는 함수\n",
    "    images = []\n",
    "    for angle in [0, 90, 180, 270]:\n",
    "        rotated_image = TF.rotate(image, angle)\n",
    "        images.append(rotated_image)\n",
    "    return images\n",
    "\n",
    "def gauss_noise(image_tensor, sigma=0.05):\n",
    "    # 이미지에 가우시안 노이즈를 추가하는 함수\n",
    "    noise = torch.randn(image_tensor.size()) * sigma\n",
    "    noisy_image = image_tensor + noise\n",
    "    noisy_image = torch.clamp(noisy_image, 0, 1)\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "class VAECustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None, gauss_sigma=0.05):\n",
    "        # 데이터셋 초기화\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "        self.gauss_sigma = gauss_sigma\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 길이를 반환\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 주어진 인덱스에 해당하는 데이터를 반환\n",
    "        image = Image.open(self.file_paths[idx])\n",
    "        if self.transform:\n",
    "            # 변환이 주어진 경우\n",
    "            original_image = self.transform(image)  # 원본 이미지 변환\n",
    "            noisy_image = gauss_noise(original_image, self.gauss_sigma)  # 노이즈 추가 이미지 생성\n",
    "            images = rotate_images(image)  # 회전 이미지 생성\n",
    "            transformed_images = [self.transform(img) for img in images]  # 회전 이미지를 변환\n",
    "            noisy_images = [gauss_noise(img, self.gauss_sigma) for img in transformed_images]  # 회전된 이미지에 노이즈 추가\n",
    "            return original_image, noisy_image, transformed_images, noisy_images\n",
    "        else:\n",
    "            # 변환이 주어지지 않은 경우 원본 이미지 반환\n",
    "            return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root=CFG.pre_data_dir, train=True, download=True,\n",
    "                                        transform=CFG.transform_pre)\n",
    "train_loader = DataLoader(dataset=trainset,batch_size=CFG.batch_size, shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로 설정\n",
    "folder = CFG.normal_root_dir\n",
    "file_path = glob.glob(os.path.join(folder, \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(file_path))\n",
    "test_size = len(file_path) - train_size\n",
    "\n",
    "train_paths, test_paths = random_split(file_path, [train_size, test_size])\n",
    "\n",
    "train_dataset = VAECustomDataset(file_paths=train_paths, transform=CFG.transform)\n",
    "test_dataset = VAECustomDataset(file_paths=test_paths, transform=CFG.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters: 25337.0000\n"
     ]
    }
   ],
   "source": [
    "# using linear layer : The number of parameters: 968903145.0000\n",
    "# only conv layer : The number of parameters: 195025.0000\n",
    "neuralnet = nnet(height=CFG.height, width=CFG.width, channel=CFG.channel,\n",
    "                 device=CFG.device, ngpu=CFG.ngpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Encoder                                  [32, 16, 5, 5]            --\n",
       "├─Sequential: 1-1                        [32, 16, 5, 5]            --\n",
       "│    └─Conv2d: 2-1                       [32, 4, 480, 480]         40\n",
       "│    └─ELU: 2-2                          [32, 4, 480, 480]         --\n",
       "│    └─Conv2d: 2-3                       [32, 4, 480, 480]         148\n",
       "│    └─ELU: 2-4                          [32, 4, 480, 480]         --\n",
       "│    └─MaxPool2d: 2-5                    [32, 4, 240, 240]         --\n",
       "│    └─Conv2d: 2-6                       [32, 8, 240, 240]         296\n",
       "│    └─ELU: 2-7                          [32, 8, 240, 240]         --\n",
       "│    └─Conv2d: 2-8                       [32, 8, 240, 240]         584\n",
       "│    └─ELU: 2-9                          [32, 8, 240, 240]         --\n",
       "│    └─MaxPool2d: 2-10                   [32, 8, 60, 60]           --\n",
       "│    └─Conv2d: 2-11                      [32, 16, 60, 60]          1,168\n",
       "│    └─ELU: 2-12                         [32, 16, 60, 60]          --\n",
       "│    └─Conv2d: 2-13                      [32, 16, 60, 60]          2,320\n",
       "│    └─ELU: 2-14                         [32, 16, 60, 60]          --\n",
       "│    └─MaxPool2d: 2-15                   [32, 16, 15, 15]          --\n",
       "│    └─Conv2d: 2-16                      [32, 16, 15, 15]          2,320\n",
       "│    └─ELU: 2-17                         [32, 16, 15, 15]          --\n",
       "│    └─Conv2d: 2-18                      [32, 16, 15, 15]          2,320\n",
       "│    └─ELU: 2-19                         [32, 16, 15, 15]          --\n",
       "│    └─MaxPool2d: 2-20                   [32, 16, 5, 5]            --\n",
       "==========================================================================================\n",
       "Total params: 9,196\n",
       "Trainable params: 9,196\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 3.44\n",
       "==========================================================================================\n",
       "Input size (MB): 29.49\n",
       "Forward/backward pass size (MB): 739.12\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 768.65\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(neuralnet.encoder, input_size=(32, 1, 480, 480), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Decoder                                  [32, 1, 480, 480]         --\n",
       "├─Sequential: 1-1                        [32, 16, 5, 5]            --\n",
       "│    └─Conv2d: 2-1                       [32, 16, 5, 5]            2,320\n",
       "│    └─ELU: 2-2                          [32, 16, 5, 5]            --\n",
       "├─Sequential: 1-2                        --                        --\n",
       "│    └─Conv2d: 2-3                       [32, 16, 5, 5]            2,320\n",
       "│    └─ELU: 2-4                          [32, 16, 5, 5]            --\n",
       "│    └─Conv2d: 2-5                       [32, 16, 5, 5]            2,320\n",
       "│    └─ELU: 2-6                          [32, 16, 5, 5]            --\n",
       "│    └─Upsample: 2-7                     [32, 16, 15, 15]          --\n",
       "│    └─Conv2d: 2-8                       [32, 16, 15, 15]          2,320\n",
       "│    └─ELU: 2-9                          [32, 16, 15, 15]          --\n",
       "│    └─Conv2d: 2-10                      [32, 16, 15, 15]          2,320\n",
       "│    └─ELU: 2-11                         [32, 16, 15, 15]          --\n",
       "│    └─Upsample: 2-12                    [32, 16, 60, 60]          --\n",
       "│    └─Conv2d: 2-13                      [32, 16, 60, 60]          2,320\n",
       "│    └─ELU: 2-14                         [32, 16, 60, 60]          --\n",
       "│    └─Conv2d: 2-15                      [32, 8, 60, 60]           1,160\n",
       "│    └─ELU: 2-16                         [32, 8, 60, 60]           --\n",
       "│    └─Upsample: 2-17                    [32, 8, 240, 240]         --\n",
       "│    └─Conv2d: 2-18                      [32, 8, 240, 240]         584\n",
       "│    └─ELU: 2-19                         [32, 8, 240, 240]         --\n",
       "│    └─Conv2d: 2-20                      [32, 4, 240, 240]         292\n",
       "│    └─ELU: 2-21                         [32, 4, 240, 240]         --\n",
       "│    └─Upsample: 2-22                    [32, 4, 480, 480]         --\n",
       "│    └─Conv2d: 2-23                      [32, 4, 480, 480]         148\n",
       "│    └─ELU: 2-24                         [32, 4, 480, 480]         --\n",
       "│    └─Conv2d: 2-25                      [32, 1, 480, 480]         37\n",
       "│    └─ELU: 2-26                         [32, 1, 480, 480]         --\n",
       "==========================================================================================\n",
       "Total params: 16,141\n",
       "Trainable params: 16,141\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 3.42\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 496.13\n",
       "Params size (MB): 0.06\n",
       "Estimated Total Size (MB): 496.24\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(neuralnet.decoder, input_size=(32, 16, 5, 5), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(neuralnet, train_loader, epochs):\n",
    "    neuralnet.train(mode=True)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for i, (inputs, _) in enumerate(train_loader):\n",
    "            input = inputs.to(device=CFG.device)\n",
    "            enc, mu, sigma = neuralnet.encoder(input)\n",
    "            x_hat = neuralnet.decoder(enc)\n",
    "            loss = loss_function(\n",
    "                x=input, x_hat=x_hat, mu=mu, sigma=sigma\n",
    "            )\n",
    "            neuralnet.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            neuralnet.optimizer.step()\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                print(f'Epoch : [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    torch.save(neuralnet.state_dict(), 'vae_cifar10_pretrained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneuralnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneuralnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mpretrain\u001b[1;34m(neuralnet, train_loader, epochs)\u001b[0m\n\u001b[0;32m      2\u001b[0m neuralnet\u001b[38;5;241m.\u001b[39mtrain(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mneuralnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\connection.py:895\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    892\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    893\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 895\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    897\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\uyeon\\anaconda3\\envs\\pytorch\\Lib\\multiprocessing\\connection.py:827\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    825\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 827\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    829\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pretrain(neuralnet=neuralnet, train_loader=train_loader, epochs=CFG.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_and_testing(neuralnet=neuralnet ,train_dataset=train_dataset, test_dataset= test_dataset,\n",
    "                      epochs=CFG.epochs, batch_size=CFG.batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
