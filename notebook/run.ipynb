{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.Training import training_and_testing\n",
    "from py.vae import NeuralNet as nnet\n",
    "import py.config as CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rc('font', family='NanumGothic')\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_images(image):\n",
    "    # 이미지를 0도, 90도, 180도, 270도로 회전시키는 함수\n",
    "    images = []\n",
    "    for angle in [0, 90, 180, 270]:\n",
    "        rotated_image = TF.rotate(image, angle)\n",
    "        images.append(rotated_image)\n",
    "    return images\n",
    "\n",
    "def gauss_noise(image_tensor, sigma=0.05):\n",
    "    # 이미지에 가우시안 노이즈를 추가하는 함수\n",
    "    noise = torch.randn(image_tensor.size()) * sigma\n",
    "    noisy_image = image_tensor + noise\n",
    "    noisy_image = torch.clamp(noisy_image, 0, 1)\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "class VAECustomDataset(Dataset):\n",
    "    def __init__(self, file_paths, transform=None, gauss_sigma=0.05):\n",
    "        # 데이터셋 초기화\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "        self.gauss_sigma = gauss_sigma\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 길이를 반환\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 주어진 인덱스에 해당하는 데이터를 반환\n",
    "        image = Image.open(self.file_paths[idx])\n",
    "        if self.transform:\n",
    "            # 변환이 주어진 경우\n",
    "            original_image = self.transform(image)  # 원본 이미지 변환\n",
    "            noisy_image = gauss_noise(original_image, self.gauss_sigma)  # 노이즈 추가 이미지 생성\n",
    "            images = rotate_images(image)  # 회전 이미지 생성\n",
    "            transformed_images = [self.transform(img) for img in images]  # 회전 이미지를 변환\n",
    "            noisy_images = [gauss_noise(img, self.gauss_sigma) for img in transformed_images]  # 회전된 이미지에 노이즈 추가\n",
    "            return original_image, noisy_image, transformed_images, noisy_images\n",
    "        else:\n",
    "            # 변환이 주어지지 않은 경우 원본 이미지 반환\n",
    "            return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로 설정\n",
    "folder = r\"D:\\PPJ\\Model\\data\\Normal\"\n",
    "file_path = glob.glob(os.path.join(folder, \"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(file_path))\n",
    "test_size = len(file_path) - train_size\n",
    "\n",
    "train_paths, test_paths = random_split(file_path, [train_size, test_size])\n",
    "\n",
    "train_dataset = VAECustomDataset(file_paths=train_paths, transform=CFG.transform)\n",
    "test_dataset = VAECustomDataset(file_paths=test_paths, transform=CFG.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (encoder_conv): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Conv2d(16, 16, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(16, 32, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (6): ELU(alpha=1.0)\n",
      "    (7): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (8): ELU(alpha=1.0)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(32, 64, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (11): ELU(alpha=1.0)\n",
      "    (12): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (13): ELU(alpha=1.0)\n",
      "  )\n",
      "  (encoder_dense): Sequential(\n",
      "    (0): Flatten()\n",
      "    (1): Linear(in_features=921600, out_features=512, bias=True)\n",
      "    (2): ELU(alpha=1.0)\n",
      "    (3): Linear(in_features=512, out_features=40, bias=True)\n",
      "  )\n",
      ")\n",
      "Decoder(\n",
      "  (decoder_dense): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=512, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=512, out_features=921600, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "  )\n",
      "  (decoder_conv): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Conv2d(64, 64, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): Conv2d(32, 32, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (7): ELU(alpha=1.0)\n",
      "    (8): ConvTranspose2d(32, 16, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
      "    (9): ELU(alpha=1.0)\n",
      "    (10): Conv2d(16, 16, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (11): ELU(alpha=1.0)\n",
      "    (12): Conv2d(16, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (13): Sigmoid()\n",
      "  )\n",
      ")\n",
      "The number of parameters : 945015273\n"
     ]
    }
   ],
   "source": [
    "neuralnet = nnet(height=CFG.height, width=CFG.width, channel=CFG.channel,\n",
    "                 device=CFG.device, ngpu=CFG.ngpu, ksize=CFG.ksize, z_dim=CFG.z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_and_testing(train_dataset=train_dataset, test_dataset= test_dataset,\n",
    "                      epochs=CFG.epochs, batch_size=CFG.batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
